{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate if the split (train-test) has common data, respectively determine share\n",
    "def evaluate_split_congruence(x_train, x_test):\n",
    "    \n",
    "    n_test = x_test.shape[0]\n",
    "    n_match = 0\n",
    "    train_lst = x_train.tolist()\n",
    "    test_lst = x_test.tolist()\n",
    "    for i in range(n_test):\n",
    "        if test_lst[i] in train_lst:\n",
    "            n_match+=1\n",
    "    \n",
    "    return n_match/n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get references for MSE or AE Values\n",
    "# I.E. Tranfer constant relative discrepancy (given %) per time point \n",
    "# to MSE or AE\n",
    "\n",
    "def relate_loss(data, discrepancy, measure = 'mse'):\n",
    "    val = 0\n",
    "    if measure == 'mse':\n",
    "        val = (np.square(discrepancy*data.flatten())).mean()\n",
    "    elif measure ==  'mae':\n",
    "         val = (np.abs(discrepancy*data.flatten())).mean()  \n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic: Compare different Settings for Models, Ensembles etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a prediction, a target and information about the underlying model's configuration, i.e. Usage of Dropout or\n",
    "# a Lambda-Scaling Layer, this function returns a list of properties for SE or AE\n",
    "# This list will eventually be added to a table, to compare models with different configurations\n",
    "\n",
    "def calc_row_df(prediction, target, measure_type = 'absolute_error',lambda_layer = True, dropout_layer = True, \n",
    "                option_relative = False,row_name = None):\n",
    "    \n",
    "    metric = 0\n",
    "    if measure_type == 'absolute_error':\n",
    "        metric = (np.abs(prediction-target)).flatten()\n",
    "    elif measure_type == 'squared_error':\n",
    "        metric = (np.square(prediction-target)).flatten()\n",
    "    else:\n",
    "        print('Measure_type unknown')\n",
    "        return\n",
    "    \n",
    "    statistic = describe(metric)\n",
    "    if lambda_layer ==True:\n",
    "        lambda_layer = 'yes'\n",
    "    else:\n",
    "        lambda_layer = 'no'\n",
    "    if dropout_layer ==True:\n",
    "        dropout_layer = 'yes'\n",
    "    else:\n",
    "        dropout_layer = 'no'\n",
    "    \n",
    "    if row_name == None:\n",
    "        return dropout_layer, lambda_layer, statistic[1][0], statistic[1][1], statistic[2], statistic[3]\n",
    "    else:\n",
    "        return dropout_layer, lambda_layer,[statistic[1][0], statistic[1][1], statistic[2], statistic[3]], row_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes and trains rnn models of different configurations, i.e. Dropout (yes/no) and \n",
    "# Scaling (yes/no)\n",
    "# The data analysis relies on the 'calc_row_df'-function.\n",
    "# It eventually returns a dataframe with 4 rows (for the 4 model types) and \n",
    "# 6 columns (recording the model configuration and Min/Max/Mean/Var of the absolute error per time point)\n",
    "\n",
    "def rnn_single_dim_config_eval(x, y, x_test,y_test, scale, epochs, batch_size, nodes_hidden, \n",
    "                               final_dense_layer=True, dense_act_fct = 'linear', act_fct_special = False,\n",
    "                               dropout_val = [0.2,0.2],val_share = 0.25, measure_type = 'absolute_error'):\n",
    "    \n",
    "    if len(nodes_hidden) > len(dropout_val):\n",
    "        print('No. of dropouts not sufficient for depth of model!' )\n",
    "        return\n",
    "    \n",
    "    INPUT = Input(shape =x.shape[1:3] )\n",
    "    \n",
    "    # No Dropout, No Lambda Layer\n",
    "    rnn_1 = create_rnn_model(model_input = INPUT, nodes = nodes_hidden, n_output = y.shape[1], \n",
    "                             final_dense_layer= final_dense_layer, dense_act_fct = dense_act_fct, \n",
    "                             act_fct_special= act_fct_special,\n",
    "                             lambda_layer=False, dropout_option=False, dropout_share=dropout_val)\n",
    "    \n",
    "    \n",
    "    #create_rnn_model(model_input=INPUT,nodes= [n_output], n_output=n_output, \n",
    "    #                           final_dense_layer = True,dense_act_fct= ThresholdedReLU(theta=-1.0),\n",
    "    #                           act_fct_special= True, optimizer_type= 'adam',loss_type='mse', \n",
    "    #                           metric_type='mae', dropout_option=False, dropout_share=[0.2,0.2], \n",
    "    #                           lambda_layer = True, lambda_scale =V_max, log_scale=True)\n",
    "    \n",
    "    \n",
    "    # scale targets y\n",
    "    #rnn_1_hist = rnn_1.fit(x, (2*y/scale-1), batch_size = batch_size, epochs = epochs, \n",
    "    #                       validation_split=val_share, verbose=0) #, callbacks=[tensorboard])\n",
    "    #pred_1 = (rnn_1.predict(x_test)+1)/2*scale # Rescale output to compare to actual target\n",
    "\n",
    "    # Use raw target\n",
    "    rnn_1_hist = rnn_1.fit(x, y, batch_size = batch_size, epochs = epochs, \n",
    "                           validation_split=val_share, verbose=0) #, callbacks=[tensorboard])\n",
    "    pred_1 = rnn_1.predict(x_test)\n",
    "\n",
    "    \n",
    "    # Dropout, No Lambda Layer\n",
    "    rnn_2 = create_rnn_model(model_input = INPUT, nodes = nodes_hidden, n_output = y.shape[1], \n",
    "                             final_dense_layer= final_dense_layer, dense_act_fct = dense_act_fct, \n",
    "                             act_fct_special=act_fct_special,\n",
    "                             lambda_layer=False, dropout_option=True, dropout_share=dropout_val)\n",
    "    # scale targets y\n",
    "    #rnn_2_hist = rnn_2.fit(x, (2*y/scale-1), batch_size, epochs = epochs, validation_split=val_share, \n",
    "    #                       verbose=0)\n",
    "    #pred_2 = (rnn_2.predict(x_test)+1)/2*scale # Rescale output to compare to actual target\n",
    "    \n",
    "    # Use raw target\n",
    "    rnn_2_hist = rnn_2.fit(x, y, batch_size, epochs = epochs, validation_split=val_share, \n",
    "                           verbose=0)\n",
    "    pred_2 = rnn_2.predict(x_test)\n",
    "    \n",
    "    \n",
    "    # No Dropout, Lambda Layer\n",
    "    rnn_3 =  create_rnn_model(model_input = INPUT, nodes = nodes_hidden, n_output = y.shape[1], \n",
    "                             final_dense_layer= final_dense_layer, dense_act_fct = dense_act_fct,\n",
    "                              act_fct_special=act_fct_special,\n",
    "                             lambda_layer=True, lambda_scale = scale,\n",
    "                              dropout_option=False, dropout_share=dropout_val)\n",
    "    rnn_3_hist = rnn_3.fit(x, y, batch_size = batch_size, epochs = epochs, validation_split=val_share, \n",
    "                           verbose=0)\n",
    "    pred_3 = rnn_3.predict(x_test)\n",
    "    \n",
    "    # Dropout, Lambda Layer\n",
    "    rnn_4 =  create_rnn_model(model_input = INPUT, nodes = nodes_hidden, n_output = y.shape[1], \n",
    "                             final_dense_layer= final_dense_layer, dense_act_fct = dense_act_fct, \n",
    "                              act_fct_special=act_fct_special,\n",
    "                             lambda_layer=True, lambda_scale = scale, \n",
    "                              dropout_option=True, dropout_share=dropout_val)\n",
    "    rnn_4_hist = rnn_4.fit(x, y, batch_size, epochs = epochs, validation_split=val_share, verbose=0)\n",
    "    pred_4 = rnn_4.predict(x_test)\n",
    "    \n",
    "    # Evaluate Results\n",
    "    \n",
    "    # Summarize Results in Table\n",
    "    dict_pred = {0: [pred_1,False,False], 1: [pred_2,True, False],2: [pred_3, False, True],\n",
    "                 3: [pred_4, True, True]}\n",
    "    if measure_type == 'absolute_error':\n",
    "        df = pd.DataFrame(data=None, index = None, \n",
    "                      columns = [ 'Dropout','Scaling Layer','min AE','max AE','MAE','Var(AE)'] )\n",
    "    if measure_type == 'squared_error':\n",
    "        df = pd.DataFrame(data=None, index = None, \n",
    "                      columns = [ 'Dropout','Scaling Layer','min SE','max SE','MSE','Var(SE)'] )\n",
    "    for i in range(4):\n",
    "        df.loc['Model {}'.format(i)] = (calc_row_df(dict_pred[i][0], y_test,dropout_layer= dict_pred[i][1], \n",
    "                                                    lambda_layer=dict_pred[i][2],measure_type= measure_type))\n",
    "\n",
    "    \n",
    "    return df,[rnn_1, rnn_2, rnn_3, rnn_4],[rnn_1_hist, rnn_2_hist, rnn_3_hist, rnn_4_hist],[pred_1, pred_2, pred_3, pred_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Several Single-, Ensemble- and Ensemble incl. Qual. - Models perform descriptive analysis\n",
    "## For Non-Zero Target Values (which are optionally above a threshold): Look at Absolute Error per\n",
    "## timepoint relative to the target value.\n",
    "## For Zero-Target Values (or optionally target values below threshold): Look at Absolute Error per time point\n",
    "## Optionally: Also include a Weighted Relative (Absolute) Error (WRAE) where\n",
    "## WRAE = target/sum(targets at given time) * error for contract at given time\n",
    "\n",
    "def create_df_model_comparison(model_single_lst,x_test, y_test, model_ens_lst = [None], \n",
    "                               model_ens_qual_lst = [None], model_plain_lst = [None], x_test_plain = None,\n",
    "                               threshold = 0, wre_measure_option = True,\n",
    "                               discount_option = False, names_number_adj = None, names_loss_adj = None,\n",
    "                               names_number_plain = None, names_loss_plain = None,\n",
    "                               discount_val = 1, version = 'new'):\n",
    "    \n",
    "    #Error catching, if no names of loss functions or number of models in ensemble provided\n",
    "    if names_number_adj == None:\n",
    "        names_number_adj = ['']*len(model_ens_lst)\n",
    "        names_loss_adj = ['']*len(model_ens_lst)\n",
    "        \n",
    "    if names_number_plain == None:\n",
    "        names_number_plain = ['']*len(model_ens_lst)\n",
    "        names_loss_plain = ['']*len(model_ens_lst)\n",
    "    \n",
    "    # initialize variables to use for later storage purposes\n",
    "    n_lst = len(model_single_lst)\n",
    "    pred = []\n",
    "    pred_ens = []\n",
    "    pred_ens_qual = []\n",
    "    pred_plain=[]\n",
    "    diff = []\n",
    "    diff_ens = []\n",
    "    diff_ens_qual = []\n",
    "    diff_plain = []\n",
    "    wre = []\n",
    "    wre_ens = []\n",
    "    wre_ens_qual =[]\n",
    "    wre_plain = []\n",
    "    \n",
    "    row = []\n",
    "    # Determine where target zero and where non-zero -> only for old version, where we looked at two error \n",
    "    # namely, part matured (-> relative error) and part non-matured (-> absolute error)\n",
    "    # In the new version we generalize this by using the weighted relative error\n",
    "    index_rel = y_test!=0#.flatten()!= 0\n",
    "    index_abs = y_test==0#.flatten()== 0\n",
    "    index_th = y_test>=threshold#.flatten()>=threshold\n",
    "    \n",
    "    # Determine times where at least one contract is still active, \n",
    "    # i.e. time\n",
    "    #where we can calculate the weighted error w.r.t. the sum of reserves at that point in time\n",
    "    index_pv_cum = (y_test.sum(axis=0)>0)\n",
    "    y_test_cum = y_test.sum(axis=0)[index_pv_cum]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if version == 'new': ## Only look at Weighted Relative Error\n",
    "        df = pd.DataFrame(data=None, index = None, columns = ['Loss','$N_{Ens}$','min diff${}_t$','max diff${}_t$',\n",
    "                                                              r'$\\widehat{\\text{Bias}}$', \n",
    "                                                              r'$\\widehat{\\text{Var}}(\\hat{f})$',\n",
    "                                                              'min WRE${}_t$','mean WRE${}_t$','max WRE${}_t$'] )\n",
    "        \n",
    "        # For all standard (individual) Models do as follows:\n",
    "        for i in range(n_lst):\n",
    "            # Calculate Predictions\n",
    "            pred.append(model_single_lst[i].predict(x_test))\n",
    "            # Calculate Errors for Zero-Target Time Points and Non-Zero Target Time Points seperately\n",
    "            diff.append(pred[i]-y_test)#.flatten()\n",
    "            wre.append(diff[i][:,index_pv_cum]/y_test_cum)\n",
    "            if discount_option:\n",
    "                # discount each year j by (discount factor)^j # No discounting included, discount_val = 1\n",
    "                wre[i] = wre[i]/discount_val**np.linspace(0,index_pv_cum.sum()-1, index_pv_cum)\n",
    "            \n",
    "            # add statistics to table\n",
    "            df.loc['EA 0{}'.format(i)] = ('MSE', '1',\n",
    "                                                   diff[i].flatten().min(), diff[i].flatten().max(),\n",
    "                                                    diff[i].flatten().mean(), pred[i].var(),\n",
    "                                                    wre[i].flatten().min(), wre[i].flatten().mean(), \n",
    "                                                    wre[i].flatten().max())\n",
    "            \n",
    "        # Option Model Ensemble: \n",
    "        if model_ens_lst[0] != None:\n",
    "            for i in range(len(model_ens_lst)):\n",
    "                pred_ens.append(model_ens_lst[i].predict(x_test))\n",
    "                diff_ens.append(pred_ens[i]-y_test)#.flatten()\n",
    "                wre_ens.append(diff_ens[i][:,index_pv_cum]/y_test_cum)\n",
    "                if discount_option:\n",
    "                    # discount each year j by (discount factor)^j\n",
    "                    wre_ens[i] = wre_ens[i]/discount_val**np.linspace(0,index_pv_cum.sum()-1, index_pv_cum)\n",
    "                \n",
    "                # Write statistics in table\n",
    "                df.loc['EA {}'.format(i)] = (names_loss_adj[i], names_number_adj[i],\n",
    "                                                   diff_ens[i].flatten().min(), diff_ens[i].flatten().max(),\n",
    "                                                   diff_ens[i].flatten().mean(), pred_ens[i].var(),\n",
    "                                                   wre_ens[i].flatten().min(), wre_ens[i].flatten().mean(), \n",
    "                                                   wre_ens[i].flatten().max())\n",
    "        \n",
    "        # Option Model Ensemble incl Qualitative Model\n",
    "        if model_ens_qual_lst[0] != None:\n",
    "            for i in range(len(model_ens_qual_lst)):\n",
    "                pred_ens_qual.append(model_ens_qual_lst[i].predict(x = [x_test])) #, x_test[:,:,2:4]]))\n",
    "                diff_ens_qual.append(pred_ens_qual[i]-y_test)#.flatten()\n",
    "                wre_ens_qual.append(diff_ens_qual[i][:,index_pv_cum]/y_test_cum)\n",
    "                if discount_option:\n",
    "                    # discount each year j by (discount factor)^j\n",
    "                    wre_ens_qual[i] = wre_ens_qual[i]/discount_val**np.linspace(0,index_pv_cum.sum()-1, index_pv_cum)\n",
    "\n",
    "                # ENter statistics in table\n",
    "                df.loc['EAQ {}'.format(i)] = (names_loss_adj[i], names_number_adj[i],\n",
    "                                                            diff_ens_qual[i].flatten().min(), \n",
    "                                                            diff_ens_qual[i].flatten().max(),\n",
    "                                                            diff_ens_qual[i].flatten().mean(),\n",
    "                                                            pred_ens_qual[i].flatten().var(),\n",
    "                                                            wre_ens_qual[i].flatten().min(), \n",
    "                                                            wre_ens_qual[i].flatten().mean(), \n",
    "                                                            wre_ens_qual[i].flatten().max())\n",
    "\n",
    "        # Option Model Ensemble with plain, repetitive Input\n",
    "        if model_plain_lst[0] != None:\n",
    "            for i in range(len(model_plain_lst)):\n",
    "                pred_plain.append(model_plain_lst[i].predict(x = [x_test_plain])) #, x_test[:,:,2:4]]))\n",
    "                diff_plain.append(pred_plain[i]-y_test)#.flatten()\n",
    "                wre_plain.append(diff_plain[i][:,index_pv_cum]/y_test_cum)\n",
    "                if discount_option:\n",
    "                    # discount each year j by (discount factor)^j\n",
    "                    wre_plain[i] = wre_plain[i]/discount_val**np.linspace(0,index_pv_cum.sum()-1, index_pv_cum)\n",
    "\n",
    "                # ENter statistics in table\n",
    "                df.loc['EP {}'.format(i)] = (names_loss_plain[i], names_number_plain[i],\n",
    "                                                         diff_plain[i].flatten().min(), \n",
    "                                                         diff_plain[i].flatten().max(),\n",
    "                                                         diff_plain[i].flatten().mean(),\n",
    "                                                         pred_plain[i].flatten().var(),\n",
    "                                                         wre_plain[i].flatten().min(), \n",
    "                                                         wre_plain[i].flatten().mean(), \n",
    "                                                         wre_plain[i].flatten().max())\n",
    "                \n",
    "        return df, [diff, diff_ens, diff_ens_qual], [wre, wre_ens, wre_ens_qual]\n",
    "                \n",
    "               \n",
    "\n",
    "    ##### Old Version of Code, for quality control purpose ####  \n",
    "    elif version == 'old': ## Old Version with RAE, AE and WRAE (including Variances)\n",
    "    \n",
    "        df = pd.DataFrame(data=None, index = None, columns = ['min RE','MRE','Max. RE',\n",
    "                                                              'Min. Diff.','Mean Diff.','Max. Diff',\n",
    "                                                              'Bias', 'Variance'] )\n",
    "        \n",
    "\n",
    "        # For all standard (individual) Models do as follows:\n",
    "        for i in range(n_lst):\n",
    "            # Calculate Predictions\n",
    "            pred.append(model_single_lst[i].predict(x_test))\n",
    "            # Calculate Errors for Zero-Target Time Points and Non-Zero Target Time Points seperately\n",
    "            diff = (pred[i]-y_test)#.flatten()\n",
    "            diff_rel = diff[index_rel & index_th]/y_test[index_rel & index_th]#.flatten())[index_rel & index_th]\n",
    "            diff_abs = diff[index_abs | np.logical_not(index_th)]\n",
    "\n",
    "            df.loc['Model {}'.format(i)] = (diff_rel.min(),diff_rel.mean(), diff_rel.max(), \n",
    "                                            diff_abs.min(), diff_abs.mean(), diff_abs.max(),\n",
    "                                            diff.mean(), pred[i].var())                                          \n",
    "\n",
    "\n",
    "        # Option Model Ensemble: \n",
    "        if model_ens_lst[0] != None:\n",
    "            for i in range(len(model_ens_lst)):\n",
    "                pred_ens.append(model_ens_lst[i].predict(x_test))\n",
    "                diff_ens = (pred_ens[i]-y_test)#.flatten()\n",
    "                diff_ens_rel = diff_ens[index_rel & index_th]/y_test[index_rel & index_th]#.flatten())[index_rel & index_th]\n",
    "                diff_ens_abs = diff_ens[index_abs | np.logical_not(index_th)]\n",
    "                df.loc['Model Ensemble {}'.format(i)] = (diff_ens_rel.min(),diff_ens_rel.mean(), \n",
    "                                                         diff_ens_rel.max(), \n",
    "                                            diff_ens_abs.min(), diff_ens_abs.mean(), diff_ens_abs.max(),\n",
    "                                            diff_ens.mean(), pred_ens[i].var())                \n",
    "\n",
    "        # Option Model Ensemble incl Qualitative Model\n",
    "        if model_ens_qual_lst[0] != None:\n",
    "            for i in range(len(model_ens_qual_lst)):\n",
    "                pred_ens_qual.append(model_ens_qual_lst[i].predict(x = [x_test])) #, x_test[:,:,2:4]]))\n",
    "                diff_ens_qual = (pred_ens_qual[i]-y_test)#.flatten()\n",
    "                diff_ens_qual_rel = diff_ens_qual[index_rel & index_th]/y_test[index_rel & index_th]#.flatten())[index_rel & index_th]\n",
    "                diff_ens_qual_abs = diff_ens_qual[index_abs | np.logical_not(index_th)]\n",
    "                \n",
    "                df.loc['Model Quant.&Qual. {}'.format(i)] = (diff_ens_qual_rel.min(),diff_ens_qual_rel.mean(), \n",
    "                                                             diff_ens_qual_rel.max(), \n",
    "                                            diff_ens_qual_abs.min(), diff_ens_qual_abs.mean(), \n",
    "                                                             diff_ens_qual_abs.max(),\n",
    "                                            diff_ens_qual.mean(), pred_ens_qual[i].var())\n",
    "            #### end version 'old\n",
    "    else:\n",
    "        print('Unknown Version.')\n",
    "        pass\n",
    "    \n",
    "    return df, [pred, pred_ens, pred_ens_qual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to evaluate the fit of a given model w.r.t. the target values\n",
    "# Aim: We want to examine the observation, that contracts with low reserve values have a worse fit \n",
    "# than high reserve value contracts\n",
    "\n",
    "# Procedure: compute precision (prediction-target)/ target -> per contract\n",
    "# Calculate those values only for times, where the contract has target reserve > 0 \n",
    "# i.e. exclude time 0 and time of and after maturity\n",
    "\n",
    "# Compute average precision per contract\n",
    "# Compare this to the maximal reserve value (throughout being active) of the contract\n",
    "\n",
    "# output versions: (1) statistic -> provides table with values (average values for deciles of reserve values)\n",
    "#                  (2) plot -> plots the results\n",
    "#                  (3) both\n",
    "\n",
    "\n",
    "def model_examine_indivual_fit(model, data, targets, output_option = 'plot', PV_max = 1,\n",
    "                               interval_lst = [0,0.001, 0.005, 0.01,0.2,0.4,0.6,0.8,0.9,1]):\n",
    "    \n",
    "    prediction = model.predict(x=data)\n",
    "    n_contracts = prediction.shape[0]\n",
    "    index = targets>0\n",
    "    \n",
    "    precision_avg = np.zeros(shape=(n_contracts,))\n",
    "    \n",
    "    # calculate average precision per contract\n",
    "    for i in range(n_contracts):\n",
    "        precision_avg[i] = ((prediction[i,index[i,:]]-targets[i,index[i,:]])/targets[i,index[i,:]]).mean()\n",
    "    \n",
    "    # Max Target Reserve per contract\n",
    "    targets_max = targets.max(axis=1)#implicitely assuming every contract has at least one year with target >0 \n",
    "    \n",
    "    if (output_option =='statistic') | (output_option == 'both'):\n",
    "        targets_max_overall = targets_max.max()\n",
    "        n_stat = len(interval_lst)\n",
    "        stat_columns = [None]*(n_stat-1)\n",
    "        for i in range(1,n_stat):\n",
    "            stat_columns[i-1] = '{}-{}'.format(interval_lst[i-1], interval_lst[i])\n",
    "        \n",
    "        df = pd.DataFrame(data=None, index = None, columns = stat_columns )\n",
    "        \n",
    "        # Calculate average of average precisions per intervals (of contracts' max reserves)\n",
    "        row_avg = np.zeros(shape = (n_stat-1,))\n",
    "        row_max = np.zeros(shape = (n_stat-1,))\n",
    "        row_min = np.zeros(shape = (n_stat-1,))\n",
    "        for i in range(n_stat-1):\n",
    "            index_interval = (targets_max >= targets_max_overall*interval_lst[i])&(targets_max < targets_max_overall*interval_lst[i+1])\n",
    "            row_avg[i] = precision_avg[index_interval].mean()\n",
    "            row_max[i] = precision_avg[index_interval].max()\n",
    "            row_min[i] = precision_avg[index_interval].min()\n",
    "        \n",
    "        # Add Average Precision for all intervall to dataframe\n",
    "        df.loc['mean re${}_t$'] = row_avg\n",
    "        df.loc['min re${}_t$'] = row_min # Note: Prediction - Target <0 -> Underestimation\n",
    "        df.loc['max re${}_t$'] = row_max\n",
    "        \n",
    "        if output_option != 'both':\n",
    "            return df\n",
    "        \n",
    "        \n",
    "    if (output_option =='plot') | (output_option == 'both'):\n",
    "        plt.scatter(targets_max,precision_avg )\n",
    "        plt.xlabel('Max. Reserve of Contract', fontsize = 'large')\n",
    "        plt.ylabel('Average relative Error of Contract', fontsize = 'large')\n",
    "        plt.show()\n",
    "        \n",
    "        if output_option == 'plot':\n",
    "            return\n",
    "        else:\n",
    "            return df\n",
    "        \n",
    "    else:\n",
    "        print('output_option unknown!')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Relate ensemble models to a q-value (average percentage discrepancy related to MSE or MAE)\n",
    "def relate_ens_to_q(x, y , x_plain,EA_lst = [None], EAQ_lst = [None], EP_lst = [None] ):\n",
    "    \n",
    "    stat_columns = ['']*(2+len(EA_lst)+len(EAQ_lst)+len(EP_lst))\n",
    "    row_mse  = ['']*(2+len(EA_lst)+len(EAQ_lst)+len(EP_lst))\n",
    "    row_mae = ['']*(2+len(EA_lst)+len(EAQ_lst)+len(EP_lst))\n",
    "    for i in range(len(stat_columns)):\n",
    "        if i<2:\n",
    "            if i==0:\n",
    "                stat_columns[i] = 'q=0.05'\n",
    "            elif i==1:\n",
    "                stat_columns[i] = 'q=0.01'\n",
    "            else:\n",
    "                print('Error')\n",
    "                return\n",
    "        elif i<len(EA_lst)+2:\n",
    "            stat_columns[i] = 'EA {}'.format(i-2)\n",
    "        elif i< len(EA_lst)+len(EAQ_lst)+2:\n",
    "            stat_columns[i] = 'EAQ {}'.format(i-len(EA_lst)-2)\n",
    "        else:\n",
    "            stat_columns[i] = 'EP {}'.format(i-len(EA_lst)-len(EAQ_lst)-2)\n",
    "        \n",
    "    df = pd.DataFrame(data=None, index = None, columns = stat_columns )\n",
    "    \n",
    "    row_mse[0], row_mse[1] =np.log(relate_loss(y,0.05, 'mse')), np.log(relate_loss(y,0.01, 'mse'))\n",
    "    row_mae[0], row_mae[1] =np.log(relate_loss(y,0.05, 'mae')), np.log(relate_loss(y,0.01, 'mae'))\n",
    "    for i in range(len(stat_columns)):\n",
    "        if i<2:\n",
    "            print('') #do nothing\n",
    "        elif i<len(EA_lst)+2:\n",
    "            row_mse[i] = np.log(((EA_lst[i-2].predict(x)-y)**2).mean())\n",
    "            row_mae[i] = np.log(np.abs(EA_lst[i-2].predict(x)-y).mean())\n",
    "        elif i< len(EA_lst)+len(EAQ_lst)+2:\n",
    "            row_mse[i] = np.log(((EAQ_lst[i-len(EA_lst)-2].predict(x)-y)**2).mean())\n",
    "            row_mae[i] = np.log(np.abs(EAQ_lst[i-len(EA_lst)-2].predict(x)-y).mean())\n",
    "        else:\n",
    "            row_mse[i] = np.log(((EP_lst[i-len(EA_lst)-len(EAQ_lst)-2].predict(x_plain)-y)**2).mean())\n",
    "            row_mae[i] = np.log(np.abs(EP_lst[i-len(EA_lst)-len(EAQ_lst)-2].predict(x_plain)-y).mean())\n",
    "            \n",
    "    df.loc['log(MSE)'] = row_mse\n",
    "    df.loc['log(MAE)'] = row_mae\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic: Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to visualize the fit of all clusters of the ANN approach\n",
    "# We compare: (1) Target value, (2) prediction of the ANN, \n",
    "# (3) the policy values obtained by classical actuarial methods for the representatives obtained by ANN\n",
    "# and (4) the Baseline policy value of K-Means\n",
    "\n",
    "# Input formats: targets as matrix (cumulative per cluster), cluster_members_count as vector, ann_prediction as matrix\n",
    "# ann_classical as list (for ceiled and floored representative), \n",
    "# kmeans_baseline as list (for ceiled and floored representative)(cumulative per cluster)\n",
    "# plot_type can be 'single' (each cluster indivicually) or 'cumulative' (portfolio view)\n",
    "\n",
    "\n",
    "## THis function has been improved by 'analyze_clustering' in the collection of functions 'clustering'\n",
    "\n",
    "\n",
    "def visualize_cluster_fit(targets, cluster_members_count, ann_prediction=None, \n",
    "                          ann_classical_up=None, ann_classical_low=None,\n",
    "                          kmeans_baseline_up=None, kmeans_baseline_low=None,\n",
    "                          plot_type = 'single',\n",
    "                          n_columns = 4, figsize = (20,30)):\n",
    "    \n",
    "    N_clusters = targets.shape[0]\n",
    "    \n",
    "    if plot_type == 'single':\n",
    "        fig, ax = plt.subplots(nrows = np.ceil(N_clusters/n_columns).astype('int'), \n",
    "                               ncols = n_columns, figsize = figsize)\n",
    "        ax = ax.flatten()\n",
    "\n",
    "        for i in range(N_clusters):\n",
    "            # Actual Targets\n",
    "            ax[i].plot(targets[i,:], 'r*', label = 'Target')\n",
    "            # Predicted Reserve by ANN\n",
    "            ax[i].plot(ann_prediction[i,:]*cluster_members_count[i], color = 'blue', label = 'ANN - Prediction')\n",
    "            # Reserve based on classical calculation using representative contracts of ANN approach\n",
    "            ax[i].plot(cluster_rep_rd_up_pv[i,:]*cluster_members_count[i], color = 'orange', \n",
    "                       label = 'ANN - Classical')\n",
    "            ax[i].plot(cluster_rep_rd_low_pv[i,:]*cluster_members_count[i], color = 'orange') \n",
    "            # Reserve based on K-Means clustering\n",
    "            ax[i].plot(kmeans_baseline_up[i,:], linestyle = ':', color = 'grey', \n",
    "                       label = 'K-Means Baseline')\n",
    "            ax[i].plot(kmeans_baseline_low[i,:], linestyle = ':', color = 'grey')\n",
    "            if i == 0:\n",
    "                ax[i].legend()\n",
    "    elif plot_type == 'cumulative':\n",
    "        # Look at cumulative cluster fit\n",
    "        plt.plot(targets.sum(axis=0), 'r*', label = 'Target') # not scaled by numbers\n",
    "        plt.plot((ann_prediction*cluster_members_count).sum(axis=0), label = 'ANN - Prediction')\n",
    "        plt.plot((kmeans_baseline_up).sum(axis=0), color = 'grey', linestyle = ':', \n",
    "                 label ='K-Means Baseline' )\n",
    "        plt.plot((kmeans_baseline_low).sum(axis=0), color = 'grey', linestyle = ':')\n",
    "        plt.plot((cluster_rep_rd_up_pv*count_v1).sum(axis = 0), color = 'orange', label = 'ANN - Classical')\n",
    "        plt.plot((cluster_rep_rd_low_pv*count_v1).sum(axis = 0), color = 'orange')\n",
    "        plt.legend()      \n",
    "        \n",
    "    else:\n",
    "        print('plot_type unknown!')\n",
    "        return\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
